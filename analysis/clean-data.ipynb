{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas natsort numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from natsort import natsort_keygen\n",
    "\n",
    "participant_usernames = [\n",
    "    'ejthue',\n",
    "    'amj5r6',\n",
    "    'a2vium',\n",
    "    'i2wsfv',\n",
    "    'sq2mde',\n",
    "    '4r7uba',\n",
    "    'rnp6q7',\n",
    "    'vf83re',\n",
    "    '7g99vx',\n",
    "    '4tcgxa',\n",
    "    'kv3jvq',\n",
    "    'sa896f',\n",
    "    'mg53k5',\n",
    "    'xxq7cw',\n",
    "]\n",
    "participant_ID_map = {username: f'P{i + 1}' for i, username in enumerate(participant_usernames)}\n",
    "\n",
    "participant_time_adjustments = {\n",
    "    'ejthue': {\n",
    "        'natural-language-processing': {\n",
    "            'quiz': -1 * 60\n",
    "        }\n",
    "    },\n",
    "    'amj5r6': {\n",
    "        'natural-language-processing': {\n",
    "            'interaction': -1 * 60\n",
    "        }\n",
    "    },\n",
    "    'rnp6q7': {\n",
    "        'natural-language-processing': {\n",
    "            'quiz': -3 * 60\n",
    "        }\n",
    "    },\n",
    "    '4tcgxa': {\n",
    "        'data-analysis': {\n",
    "            'interaction': -2 * 60,\n",
    "            'quiz': -3 * 60\n",
    "        }\n",
    "    },\n",
    "    'kv3jvq': {\n",
    "        'data-analysis': {\n",
    "            'quiz': -1 * 60\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process client data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw-client.json') as file:\n",
    "    client_data = json.load(file)\n",
    "\n",
    "participants_data = []\n",
    "participant_tasks_data = []\n",
    "participant_interaction_data = []\n",
    "\n",
    "for participant in client_data:\n",
    "    if participant['username'] not in participant_ID_map:\n",
    "        continue\n",
    "\n",
    "    participant_ID = participant_ID_map[participant['username']]\n",
    "    \n",
    "    # Participants (ID/group)\n",
    "    participants_data.append({\n",
    "        'participant_ID': participant_ID, \n",
    "        'group': participant['group']\n",
    "    })\n",
    "\n",
    "    # Participant tasks (time to complete interaction/quiz per taks)\n",
    "    participant_tasks = {}\n",
    "\n",
    "    for step in participant['steps']:\n",
    "        if step['key'].startswith('interaction-'):\n",
    "            type = 'interaction'\n",
    "        elif step['key'].startswith('quiz-'):\n",
    "            type = 'quiz'\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        task = step['key'].split('-', 1)[1]\n",
    "        if task not in participant_tasks:\n",
    "            participant_tasks[task] = {}\n",
    "\n",
    "        time = round((pd.to_datetime(step['endTime'], utc=True) - pd.to_datetime(step['startTime'], utc=True)).total_seconds())\n",
    "\n",
    "        participant_tasks[task][type] = time\n",
    "\n",
    "    for task, times in participant_tasks.items():\n",
    "        interaction_time = times['interaction']\n",
    "        quiz_time = times['quiz']\n",
    "\n",
    "        # Apply time adjustments\n",
    "        if participant['username'] in participant_time_adjustments and task in participant_time_adjustments[participant['username']]:\n",
    "            if 'interaction' in participant_time_adjustments[participant['username']][task]:\n",
    "                interaction_time += participant_time_adjustments[participant['username']][task]['interaction']\n",
    "            if 'quiz' in participant_time_adjustments[participant['username']][task]:\n",
    "                quiz_time += participant_time_adjustments[participant['username']][task]['quiz']\n",
    "\n",
    "        participant_tasks_data.append({\n",
    "            'participant_ID': participant_ID, \n",
    "            'task': task, \n",
    "            'interaction_time': interaction_time, \n",
    "            'quiz_time': quiz_time\n",
    "        })\n",
    "\n",
    "    # Participant interactions (input/response pairs with optional internal questions and mental state per task)\n",
    "    messages = participant['interactionMessages']\n",
    "    messages.sort(key=lambda x: x['order'])\n",
    "    participant_interaction_turns = {}\n",
    "\n",
    "    for message in messages:\n",
    "        if message['task'] not in participant_interaction_turns:\n",
    "            participant_interaction_turns[message['task']] = []\n",
    "\n",
    "        if message['type'] == 'user':\n",
    "            participant_interaction_turns[message['task']].append({\n",
    "                'input': message['content'], \n",
    "                'response': None,\n",
    "                'questions': None,\n",
    "                'mental_state': None,\n",
    "                'response_time': message['timeMS'] / 1000\n",
    "            })\n",
    "        elif message['type'] == 'ai':\n",
    "            participant_interaction_turns[message['task']][-1]['response'] = message['content']\n",
    "        elif message['type'] == 'internal':\n",
    "            if participant_interaction_turns[message['task']][-1]['questions'] is None:\n",
    "                participant_interaction_turns[message['task']][-1]['questions'] = message['content']\n",
    "            elif participant_interaction_turns[message['task']][-1]['mental_state'] is None:\n",
    "                participant_interaction_turns[message['task']][-1]['mental_state'] = message['content']\n",
    "\n",
    "    for task, turns in participant_interaction_turns.items():\n",
    "        for i, turn in enumerate(turns):\n",
    "            participant_interaction_data.append({\n",
    "                'participant_ID': participant_ID, \n",
    "                'task': task,\n",
    "                'turn': i + 1, \n",
    "                **turn\n",
    "            })\n",
    "\n",
    "client_participants_df = pd.DataFrame(participants_data)\n",
    "\n",
    "client_participant_tasks_df = pd.DataFrame(participant_tasks_data)\n",
    "client_participant_tasks_df['interaction_time'] = client_participant_tasks_df['interaction_time'].astype('Int64')\n",
    "client_participant_tasks_df['quiz_time'] = client_participant_tasks_df['quiz_time'].astype('Int64')\n",
    "\n",
    "client_participant_interaction_df = pd.DataFrame(participant_interaction_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Qualtrics data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-study survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'user': 'username',\n",
    "    'Q1': 'study_program',\n",
    "    'Q2': 'study_stage',\n",
    "    'Q3_1': 'experience_programming_estimated',\n",
    "    'Q3_7': 'experience_oop',\n",
    "    'Q3_2': 'experience_python',\n",
    "    'Q3_3': 'experience_data_analysis',\n",
    "    'Q3_5': 'experience_nlp',\n",
    "    'Q4': 'familiarity_LLM',\n",
    "    'Q5_1': 'familiarity_LLM_programming_writing',\n",
    "    'Q5_2': 'familiarity_LLM_programming_modifying',\n",
    "    'Q5_3': 'familiarity_LLM_programming_debugging',\n",
    "    'Q5_4': 'familiarity_LLM_programming_explaining',\n",
    "    'Q5_5': 'familiarity_LLM_programming_learning',\n",
    "    'Q6': 'familiarity_LLM_programming_other',\n",
    "    'Q7': 'LLM_programming_feedback',\n",
    "}\n",
    "survey_pre_df = pd.read_csv('data/raw-survey-pre.csv', skiprows=(1, 2), usecols=columns.keys()).rename(columns=columns)\n",
    "survey_pre_df['participant_ID'] = survey_pre_df['username'].map(participant_ID_map)\n",
    "survey_pre_df = survey_pre_df[~survey_pre_df['participant_ID'].isna()]\n",
    "\n",
    "survey_pre_df['familiarity_LLM'] = survey_pre_df['familiarity_LLM'].map({\n",
    "    'Never': 1,\n",
    "    'Rarely': 2,\n",
    "    'Sometimes': 3,\n",
    "    'Often': 4,\n",
    "    'Very often': 5,\n",
    "})\n",
    "\n",
    "for column in [\n",
    "    'familiarity_LLM_programming_writing',\n",
    "    'familiarity_LLM_programming_modifying',\n",
    "    'familiarity_LLM_programming_debugging',\n",
    "    'familiarity_LLM_programming_explaining',\n",
    "    'familiarity_LLM_programming_learning',\n",
    "]:\n",
    "    survey_pre_df[column] = survey_pre_df[column].map({\n",
    "        'Never': 1,\n",
    "        'Rarely': 2,\n",
    "        'Sometimes': 3,\n",
    "        'Often': 4,\n",
    "        'Almost always': 5,\n",
    "    })\n",
    "\n",
    "survey_pre_df['experience_programming'] = survey_pre_df[['experience_programming_estimated', 'experience_oop']].mean(axis=1)\n",
    "\n",
    "survey_pre_df['study_programming_oriented'] = survey_pre_df['study_program'].map({\n",
    "    'Not programming-oriented': False,\n",
    "    'Programming-oriented (Computer Science, Artificial Intelligence, etc.)': True,\n",
    "})\n",
    "survey_pre_df['study_stage'] = survey_pre_df['study_stage'].map({\n",
    "    'Master\\'s, any year': 'M',\n",
    "    'Bachelor, third year': 'B3',\n",
    "    'Bachelor, second year': 'B2',\n",
    "    'Bachelor, first year': 'B1',\n",
    "})\n",
    "\n",
    "survey_pre_df = survey_pre_df.sort_values('participant_ID', key=natsort_keygen()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quizzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_quiz(task):\n",
    "    quiz_df = pd.read_csv(f'data/raw-quiz-{task}.csv', skiprows=(1, 2)).rename(columns={'user': 'username'})\n",
    "    quiz_df['participant_ID'] = quiz_df['username'].map(participant_ID_map)\n",
    "    quiz_df = quiz_df[~quiz_df['participant_ID'].isna()]\n",
    "\n",
    "    quiz_df = quiz_df[['participant_ID'] + [column for column in quiz_df.columns if column.startswith('Q')]]\n",
    "\n",
    "    quiz_df['task'] = task\n",
    "\n",
    "    return quiz_df\n",
    "\n",
    "quiz_answers_df = pd.concat([clean_quiz('natural-language-processing'), clean_quiz('data-analysis')])\n",
    "\n",
    "quiz_answers_df = quiz_answers_df.sort_values(['participant_ID', 'task']).reset_index(drop=True)\n",
    "columns = quiz_answers_df.columns.tolist()\n",
    "columns.sort()\n",
    "columns.insert(0, columns.pop(columns.index('task')))\n",
    "columns.insert(0, columns.pop(columns.index('participant_ID')))\n",
    "quiz_answers_df = quiz_answers_df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chatbot_evaluation(chatbot):\n",
    "    columns = {\n",
    "        'user': 'username',\n",
    "        'Q1_1': 'usefulness_1',\n",
    "        'Q1_2': 'usefulness_2',\n",
    "        'Q1_3': 'usefulness_3',\n",
    "        'Q1_4': 'usefulness_4',\n",
    "        'Q1_5': 'usefulness_5',\n",
    "        'Q1_6': 'usefulness_6',\n",
    "        'Q1_7': 'ease_of_use_1',\n",
    "        'Q1_8': 'ease_of_use_2',\n",
    "        'Q1_9': 'ease_of_use_3',\n",
    "        'Q1_10': 'ease_of_use_4',\n",
    "        'Q1_11': 'ease_of_use_5',\n",
    "        'Q1_12': 'ease_of_use_6',\n",
    "        'Q2_1': 'cognitive_load_1',\n",
    "        'Q2_2': 'cognitive_load_2',\n",
    "        'Q2_3': 'cognitive_load_3',\n",
    "        'Q2_4': 'cognitive_load_4',\n",
    "        'Q2_5': 'cognitive_load_5',\n",
    "        'Q2_6': 'cognitive_load_6',\n",
    "        'Q3': 'feedback',\n",
    "    }\n",
    "\n",
    "    if chatbot == 'B':\n",
    "        columns.update({\n",
    "            'Q4': 'relative_speed',\n",
    "            'Q5': 'speed_feedback'\n",
    "        })\n",
    "\n",
    "    evaluation_df = pd.read_csv(f'data/raw-evaluation-{chatbot}.csv', skiprows=(1, 2), usecols=columns.keys()).rename(columns=columns)\n",
    "    evaluation_df['participant_ID'] = evaluation_df['username'].map(participant_ID_map)\n",
    "    evaluation_df = evaluation_df[~evaluation_df['participant_ID'].isna()]\n",
    "\n",
    "    for i in range(6):\n",
    "        for column in [\n",
    "            f'usefulness_{i + 1}',\n",
    "            f'ease_of_use_{i + 1}',\n",
    "        ]:\n",
    "            evaluation_df[column] = evaluation_df[column].map({\n",
    "                'Extremely disagree': 1,\n",
    "                'Quite disagree': 2,\n",
    "                'Slightly disagree': 3,\n",
    "                'Neither agree nor disagree': 4,\n",
    "                'Slightly agree': 5,\n",
    "                'Quite agree': 6,\n",
    "                'Extremely agree': 7,\n",
    "            })\n",
    "\n",
    "    if chatbot == 'B':\n",
    "        evaluation_df['relative_speed'] = evaluation_df['relative_speed'].map({\n",
    "            'Much slower': 1,\n",
    "            'Somewhat slower': 2,\n",
    "            'About the same': 3,\n",
    "            'Somewhat faster': 4,\n",
    "            'Much faster': 5,\n",
    "        })\n",
    "\n",
    "    evaluation_df['chatbot'] = chatbot\n",
    "\n",
    "    return evaluation_df\n",
    "\n",
    "chatbots_evaluation_df = pd.concat([clean_chatbot_evaluation('A'), clean_chatbot_evaluation('B')])\n",
    "\n",
    "columns = chatbots_evaluation_df.columns.tolist()\n",
    "columns.insert(0, columns.pop(columns.index('chatbot')))\n",
    "columns.insert(0, columns.pop(columns.index('participant_ID')))\n",
    "chatbots_evaluation_df = chatbots_evaluation_df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and save cleaned data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_df = client_participants_df.merge(\n",
    "    survey_pre_df[[\n",
    "        'participant_ID', \n",
    "        'study_programming_oriented',\n",
    "        'study_stage',\n",
    "        'experience_programming',\n",
    "        'experience_programming_estimated',\n",
    "        'experience_oop',\n",
    "        'experience_python',\n",
    "        'experience_data_analysis',\n",
    "        'experience_nlp',\n",
    "        'familiarity_LLM',\n",
    "        'familiarity_LLM_programming_writing',\n",
    "        'familiarity_LLM_programming_modifying',\n",
    "        'familiarity_LLM_programming_debugging',\n",
    "        'familiarity_LLM_programming_explaining',\n",
    "        'familiarity_LLM_programming_learning',\n",
    "        'familiarity_LLM_programming_other',\n",
    "        'LLM_programming_feedback',\n",
    "    ]], \n",
    "    on='participant_ID', \n",
    "    how='outer'\n",
    ")\n",
    "participants_df.sort_values(['participant_ID'], key=natsort_keygen()).to_csv('data/participants.csv', index=False)\n",
    "\n",
    "\n",
    "client_participant_interaction_df.sort_values(['participant_ID', 'task', 'turn'], key=natsort_keygen()).to_csv('data/interactions.csv', index=False)\n",
    " \n",
    "tasks_df = client_participant_tasks_df.merge(\n",
    "    quiz_answers_df, \n",
    "    on=['participant_ID', 'task'], \n",
    "    how='outer'\n",
    ")\n",
    "tasks_df.sort_values(['participant_ID', 'task'], key=natsort_keygen()).to_csv('data/tasks.csv', index=False)\n",
    "\n",
    "chatbots_evaluation_df.sort_values(['participant_ID', 'chatbot'], key=natsort_keygen()).to_csv('data/evaluations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Create DataFrames for design config\n",
    "with open('../task/design.json') as file:\n",
    "    design_config = json.load(file)\n",
    "\n",
    "stage_tasks_df = pd.DataFrame([\n",
    "    {'stage': stage, 'task': task}\n",
    "    for stage, stage_config in design_config['stages'].items()\n",
    "    for task in stage_config['tasks']\n",
    "])\n",
    "group_stage_models_df = pd.DataFrame([\n",
    "    {\n",
    "        'group': group,\n",
    "        'stage': stage,\n",
    "        'model': model,\n",
    "    }\n",
    "    for group, group_config in design_config['groups'].items()\n",
    "    for stage, model in group_config['models'].items()\n",
    "])\n",
    "group_task_model_df = group_stage_models_df.merge(stage_tasks_df, on='stage')[['group', 'task', 'model']]\n",
    "\n",
    "participants = pd.read_csv('data/participants.csv')\n",
    "participants.style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'white-space': 'pre-wrap',\n",
    "})\n",
    "\n",
    "interactions = pd.read_csv('data/interactions.csv')\n",
    "interactions = interactions.merge(participants_df[['participant_ID', 'group']], on=['participant_ID'])\n",
    "interactions = interactions.merge(group_task_model_df, on=['group', 'task'])\n",
    "interactions.style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'white-space': 'pre-wrap',\n",
    "})\n",
    "\n",
    "evaluations = pd.read_csv('data/evaluations.csv')\n",
    "evaluations = evaluations.merge(participants[['participant_ID', 'group']], on='participant_ID')\n",
    "evaluations['model'] = evaluations.apply(lambda row: design_config['groups'][row['group']]['models'][row['chatbot']], axis=1)\n",
    "evaluations.style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'white-space': 'pre-wrap',\n",
    "})\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan for accidental sensitive data submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_ID</th>\n",
       "      <th>task</th>\n",
       "      <th>turn</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [participant_ID, task, turn, input]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanned_participants = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14']\n",
    "interactions[~interactions['participant_ID'].isin(scanned_participants)][['participant_ID', 'task', 'turn', 'input']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-study survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_ID</th>\n",
       "      <th>familiarity_LLM_programming_other</th>\n",
       "      <th>LLM_programming_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [participant_ID, familiarity_LLM_programming_other, LLM_programming_feedback]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanned_participants = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14']\n",
    "participants[~participants['participant_ID'].isin(scanned_participants)][['participant_ID', 'familiarity_LLM_programming_other', 'LLM_programming_feedback']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_ID</th>\n",
       "      <th>chatbot</th>\n",
       "      <th>feedback</th>\n",
       "      <th>speed_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [participant_ID, chatbot, feedback, speed_feedback]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanned_participants = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14']\n",
    "evaluations[~evaluations['participant_ID'].isin(scanned_participants)][['participant_ID', 'chatbot', 'feedback', 'speed_feedback']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export coding template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('data/coding-template.xlsx') as writer:\n",
    "    participants[['participant_ID', 'familiarity_LLM_programming_other']].to_excel(writer, sheet_name='LLM_programming_other', index=False)\n",
    "    participants[['participant_ID', 'LLM_programming_feedback']].to_excel(writer, sheet_name='LLM_programming_feedback', index=False)\n",
    "    evaluations[['participant_ID', 'model', 'chatbot', 'feedback']].to_excel(writer, sheet_name='feedback', index=False)\n",
    "\n",
    "    speed_feedback_df = evaluations[evaluations['chatbot'] == 'B'][['participant_ID', 'model', 'speed_feedback']].copy()\n",
    "    speed_feedback_df['compared_to'] = evaluations['model'].apply(lambda model: 'tom' if model == 'control' else 'control')\n",
    "    speed_feedback_df[['participant_ID', 'model', 'compared_to', 'speed_feedback']].rename(columns={\n",
    "        'model': 'model B (second)',\n",
    "        'compared_to': 'compared to model A (first)'\n",
    "    }).to_excel(writer, sheet_name='speed_feedback', index=False)\n",
    "\n",
    "    interactions[['participant_ID', 'task', 'turn', 'input', 'response']].to_excel(writer, sheet_name='inputs', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
